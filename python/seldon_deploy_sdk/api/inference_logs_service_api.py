# coding: utf-8

"""
    Seldon Deploy API

    API to interact and manage the lifecycle of your machine learning models deployed through Seldon Deploy.  # noqa: E501

    OpenAPI spec version: v1alpha1
    Contact: hello@seldon.io
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""


from __future__ import absolute_import

import re  # noqa: F401

# python 2 and python 3 compatibility library
import six

from seldon_deploy_sdk.api_client import ApiClient


class InferenceLogsServiceApi(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    Ref: https://github.com/swagger-api/swagger-codegen
    """

    def __init__(self, api_client=None):
        if api_client is None:
            api_client = ApiClient()
        self.api_client = api_client

    def inference_logs_service_get_deployment_inference_logs(self, namespace, deployment_name, body, **kwargs):  # noqa: E501
        """Get inference logs for seldon deployments.  # noqa: E501

        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.inference_logs_service_get_deployment_inference_logs(namespace, deployment_name, body, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str namespace: The namespace that this seldon deployment belongs to. (required)
        :param str deployment_name: The name of the seldon deployment to get inference logs for. (required)
        :param Body1 body: (required)
        :return: V1GetDeploymentInferenceLogsResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.inference_logs_service_get_deployment_inference_logs_with_http_info(namespace, deployment_name, body, **kwargs)  # noqa: E501
        else:
            (data) = self.inference_logs_service_get_deployment_inference_logs_with_http_info(namespace, deployment_name, body, **kwargs)  # noqa: E501
            return data

    def inference_logs_service_get_deployment_inference_logs_with_http_info(self, namespace, deployment_name, body, **kwargs):  # noqa: E501
        """Get inference logs for seldon deployments.  # noqa: E501

        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.inference_logs_service_get_deployment_inference_logs_with_http_info(namespace, deployment_name, body, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str namespace: The namespace that this seldon deployment belongs to. (required)
        :param str deployment_name: The name of the seldon deployment to get inference logs for. (required)
        :param Body1 body: (required)
        :return: V1GetDeploymentInferenceLogsResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['namespace', 'deployment_name', 'body']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method inference_logs_service_get_deployment_inference_logs" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'namespace' is set
        if ('namespace' not in params or
                params['namespace'] is None):
            raise ValueError("Missing the required parameter `namespace` when calling `inference_logs_service_get_deployment_inference_logs`")  # noqa: E501
        # verify the required parameter 'deployment_name' is set
        if ('deployment_name' not in params or
                params['deployment_name'] is None):
            raise ValueError("Missing the required parameter `deployment_name` when calling `inference_logs_service_get_deployment_inference_logs`")  # noqa: E501
        # verify the required parameter 'body' is set
        if ('body' not in params or
                params['body'] is None):
            raise ValueError("Missing the required parameter `body` when calling `inference_logs_service_get_deployment_inference_logs`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'namespace' in params:
            path_params['namespace'] = params['namespace']  # noqa: E501
        if 'deployment_name' in params:
            path_params['deploymentName'] = params['deployment_name']  # noqa: E501

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        if 'body' in params:
            body_params = params['body']
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/json'])  # noqa: E501

        # HTTP header `Content-Type`
        header_params['Content-Type'] = self.api_client.select_header_content_type(  # noqa: E501
            ['application/json'])  # noqa: E501

        # Authentication setting
        auth_settings = ['OAuth2']  # noqa: E501

        return self.api_client.call_api(
            '/inference-logs/namespace/{namespace}/seldondeployments/{deploymentName}', 'POST',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='V1GetDeploymentInferenceLogsResponse',  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def inference_logs_service_get_model_inference_logs(self, namespace, pipeline_name, model_name, body, **kwargs):  # noqa: E501
        """Get inference logs for seldon models.  # noqa: E501

        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.inference_logs_service_get_model_inference_logs(namespace, pipeline_name, model_name, body, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str namespace: The namespace that this seldon deployment belongs to. (required)
        :param str pipeline_name: The name of the seldon pipeline to get inference logs for. (required)
        :param str model_name: The name of the seldon model to get inference logs for. (required)
        :param Body body: (required)
        :return: V1GetModelInferenceLogsResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.inference_logs_service_get_model_inference_logs_with_http_info(namespace, pipeline_name, model_name, body, **kwargs)  # noqa: E501
        else:
            (data) = self.inference_logs_service_get_model_inference_logs_with_http_info(namespace, pipeline_name, model_name, body, **kwargs)  # noqa: E501
            return data

    def inference_logs_service_get_model_inference_logs_with_http_info(self, namespace, pipeline_name, model_name, body, **kwargs):  # noqa: E501
        """Get inference logs for seldon models.  # noqa: E501

        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.inference_logs_service_get_model_inference_logs_with_http_info(namespace, pipeline_name, model_name, body, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str namespace: The namespace that this seldon deployment belongs to. (required)
        :param str pipeline_name: The name of the seldon pipeline to get inference logs for. (required)
        :param str model_name: The name of the seldon model to get inference logs for. (required)
        :param Body body: (required)
        :return: V1GetModelInferenceLogsResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['namespace', 'pipeline_name', 'model_name', 'body']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method inference_logs_service_get_model_inference_logs" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'namespace' is set
        if ('namespace' not in params or
                params['namespace'] is None):
            raise ValueError("Missing the required parameter `namespace` when calling `inference_logs_service_get_model_inference_logs`")  # noqa: E501
        # verify the required parameter 'pipeline_name' is set
        if ('pipeline_name' not in params or
                params['pipeline_name'] is None):
            raise ValueError("Missing the required parameter `pipeline_name` when calling `inference_logs_service_get_model_inference_logs`")  # noqa: E501
        # verify the required parameter 'model_name' is set
        if ('model_name' not in params or
                params['model_name'] is None):
            raise ValueError("Missing the required parameter `model_name` when calling `inference_logs_service_get_model_inference_logs`")  # noqa: E501
        # verify the required parameter 'body' is set
        if ('body' not in params or
                params['body'] is None):
            raise ValueError("Missing the required parameter `body` when calling `inference_logs_service_get_model_inference_logs`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'namespace' in params:
            path_params['namespace'] = params['namespace']  # noqa: E501
        if 'pipeline_name' in params:
            path_params['pipelineName'] = params['pipeline_name']  # noqa: E501
        if 'model_name' in params:
            path_params['modelName'] = params['model_name']  # noqa: E501

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        if 'body' in params:
            body_params = params['body']
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/json'])  # noqa: E501

        # HTTP header `Content-Type`
        header_params['Content-Type'] = self.api_client.select_header_content_type(  # noqa: E501
            ['application/json'])  # noqa: E501

        # Authentication setting
        auth_settings = ['OAuth2']  # noqa: E501

        return self.api_client.call_api(
            '/inference-logs/namespace/{namespace}/pipelines/{pipelineName}/models/{modelName}', 'POST',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='V1GetModelInferenceLogsResponse',  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def inference_logs_service_list_deployment_inference_logs(self, **kwargs):  # noqa: E501
        """Get inference logs metadata for seldon deployments.  # noqa: E501

        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.inference_logs_service_list_deployment_inference_logs(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str namespace: The namespace that this seldon deployment belongs to.
        :param str deployment_name: The name of the seldon deployment to get inference logs for.
        :param str predictor_name: The predictor name of the seldon deployment to get inference logs for. e.g. \"default\", \"canary\", \"shadow\"
        :param str container_name: The container name of the seldon deployment to get inference logs for. e.g. \"my-container\", \"input-transformer\", \"output-transformer\"
        :return: V1ListDeploymentInferenceLogsResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.inference_logs_service_list_deployment_inference_logs_with_http_info(**kwargs)  # noqa: E501
        else:
            (data) = self.inference_logs_service_list_deployment_inference_logs_with_http_info(**kwargs)  # noqa: E501
            return data

    def inference_logs_service_list_deployment_inference_logs_with_http_info(self, **kwargs):  # noqa: E501
        """Get inference logs metadata for seldon deployments.  # noqa: E501

        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.inference_logs_service_list_deployment_inference_logs_with_http_info(async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str namespace: The namespace that this seldon deployment belongs to.
        :param str deployment_name: The name of the seldon deployment to get inference logs for.
        :param str predictor_name: The predictor name of the seldon deployment to get inference logs for. e.g. \"default\", \"canary\", \"shadow\"
        :param str container_name: The container name of the seldon deployment to get inference logs for. e.g. \"my-container\", \"input-transformer\", \"output-transformer\"
        :return: V1ListDeploymentInferenceLogsResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['namespace', 'deployment_name', 'predictor_name', 'container_name']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method inference_logs_service_list_deployment_inference_logs" % key
                )
            params[key] = val
        del params['kwargs']

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'namespace' in params:
            query_params.append(('namespace', params['namespace']))  # noqa: E501
        if 'deployment_name' in params:
            query_params.append(('deploymentName', params['deployment_name']))  # noqa: E501
        if 'predictor_name' in params:
            query_params.append(('predictorName', params['predictor_name']))  # noqa: E501
        if 'container_name' in params:
            query_params.append(('containerName', params['container_name']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/json'])  # noqa: E501

        # HTTP header `Content-Type`
        header_params['Content-Type'] = self.api_client.select_header_content_type(  # noqa: E501
            ['application/json'])  # noqa: E501

        # Authentication setting
        auth_settings = ['OAuth2']  # noqa: E501

        return self.api_client.call_api(
            '/inference-logs/seldondeployments', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='V1ListDeploymentInferenceLogsResponse',  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def inference_logs_service_list_model_inference_logs(self, namespace, pipeline_name, model_name, **kwargs):  # noqa: E501
        """Get inference logs metadata for seldon models.  # noqa: E501

        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.inference_logs_service_list_model_inference_logs(namespace, pipeline_name, model_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str namespace: The namespace that this seldon deployment belongs to. (required)
        :param str pipeline_name: The name of the seldon pipeline to get inference logs for. (required)
        :param str model_name: The name of the seldon model to get inference logs for. (required)
        :return: V1ListModelInferenceLogsResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.inference_logs_service_list_model_inference_logs_with_http_info(namespace, pipeline_name, model_name, **kwargs)  # noqa: E501
        else:
            (data) = self.inference_logs_service_list_model_inference_logs_with_http_info(namespace, pipeline_name, model_name, **kwargs)  # noqa: E501
            return data

    def inference_logs_service_list_model_inference_logs_with_http_info(self, namespace, pipeline_name, model_name, **kwargs):  # noqa: E501
        """Get inference logs metadata for seldon models.  # noqa: E501

        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.inference_logs_service_list_model_inference_logs_with_http_info(namespace, pipeline_name, model_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str namespace: The namespace that this seldon deployment belongs to. (required)
        :param str pipeline_name: The name of the seldon pipeline to get inference logs for. (required)
        :param str model_name: The name of the seldon model to get inference logs for. (required)
        :return: V1ListModelInferenceLogsResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['namespace', 'pipeline_name', 'model_name']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method inference_logs_service_list_model_inference_logs" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'namespace' is set
        if ('namespace' not in params or
                params['namespace'] is None):
            raise ValueError("Missing the required parameter `namespace` when calling `inference_logs_service_list_model_inference_logs`")  # noqa: E501
        # verify the required parameter 'pipeline_name' is set
        if ('pipeline_name' not in params or
                params['pipeline_name'] is None):
            raise ValueError("Missing the required parameter `pipeline_name` when calling `inference_logs_service_list_model_inference_logs`")  # noqa: E501
        # verify the required parameter 'model_name' is set
        if ('model_name' not in params or
                params['model_name'] is None):
            raise ValueError("Missing the required parameter `model_name` when calling `inference_logs_service_list_model_inference_logs`")  # noqa: E501

        collection_formats = {}

        path_params = {}

        query_params = []
        if 'namespace' in params:
            query_params.append(('namespace', params['namespace']))  # noqa: E501
        if 'pipeline_name' in params:
            query_params.append(('pipelineName', params['pipeline_name']))  # noqa: E501
        if 'model_name' in params:
            query_params.append(('modelName', params['model_name']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/json'])  # noqa: E501

        # HTTP header `Content-Type`
        header_params['Content-Type'] = self.api_client.select_header_content_type(  # noqa: E501
            ['application/json'])  # noqa: E501

        # Authentication setting
        auth_settings = ['OAuth2']  # noqa: E501

        return self.api_client.call_api(
            '/inference-logs/models', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='V1ListModelInferenceLogsResponse',  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)
